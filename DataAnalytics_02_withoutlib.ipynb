{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('cosine_similaritydocs.txt','r')\n",
    "docs= file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what is your name my name is',\n",
       " 'this is here wer are here ',\n",
       " 'what is there what it is',\n",
       " 'this is similarity docs',\n",
       " 'this is similarity docs']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_list=list()\n",
    "for i in docs:\n",
    "    docs_temp=i.lower().split()\n",
    "    docs_list.append(docs_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['what', 'is', 'your', 'name', 'my', 'name', 'is'],\n",
       " ['this', 'is', 'here', 'wer', 'are', 'here'],\n",
       " ['what', 'is', 'there', 'what', 'it', 'is'],\n",
       " ['this', 'is', 'similarity', 'docs'],\n",
       " ['this', 'is', 'similarity', 'docs']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words=list()\n",
    "for i in docs_list:\n",
    "    unique_words=unique_words+i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'is',\n",
       " 'your',\n",
       " 'name',\n",
       " 'my',\n",
       " 'name',\n",
       " 'is',\n",
       " 'this',\n",
       " 'is',\n",
       " 'here',\n",
       " 'wer',\n",
       " 'are',\n",
       " 'here',\n",
       " 'what',\n",
       " 'is',\n",
       " 'there',\n",
       " 'what',\n",
       " 'it',\n",
       " 'is',\n",
       " 'this',\n",
       " 'is',\n",
       " 'similarity',\n",
       " 'docs',\n",
       " 'this',\n",
       " 'is',\n",
       " 'similarity',\n",
       " 'docs']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words_set=list(set(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'here', 'name', 'is', 'what', 'my', 'wer', 'are', 'your', 'there', 'similarity', 'docs', 'it']\n"
     ]
    }
   ],
   "source": [
    "print(unique_words_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_frequency(document,word):\n",
    "    count=0\n",
    "    for i in document:\n",
    "        if i==word:\n",
    "            count=count+1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "here\n",
      "name\n",
      "is\n",
      "what\n",
      "my\n",
      "wer\n",
      "are\n",
      "your\n",
      "there\n",
      "similarity\n",
      "docs\n",
      "it\n"
     ]
    }
   ],
   "source": [
    "size=len(unique_words_set)\n",
    "for i in range(size):\n",
    "    print(unique_words_set[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(size):\n",
    "    for j in range(len(docs_list)):\n",
    "        temp=find_frequency(docs_list[j],unique_words_set[i])\n",
    "        print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency=list()\n",
    "for i in range(size):\n",
    "    count_list=list()\n",
    "    for j in range(len(docs_list)):\n",
    "        temp=find_frequency(docs_list[j],unique_words_set[i])\n",
    "        count_list.append(temp)\n",
    "    frequency.append(count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 0, 1, 1],\n",
       " [0, 2, 0, 0, 0],\n",
       " [2, 0, 0, 0, 0],\n",
       " [2, 1, 2, 1, 1],\n",
       " [1, 0, 2, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row=unique words and columns = docs\n",
    "frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "mod=[]\n",
    "for i in range(len(docs_list)):\n",
    "    count=0\n",
    "    for j in range(len(unique_words_set)):\n",
    "        count=count+frequency[j][i]**2\n",
    "    mod.append(math.sqrt(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.3166247903554, 2.8284271247461903, 3.1622776601683795, 2.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "print(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 2, 2, 1, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       " [1, 2, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       " [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_array=np.array(frequency)\n",
    "transpose=temp_array.T\n",
    "frequency1= transpose.tolist()\n",
    "frequency1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency1\n",
    "def dot_product(a,b):\n",
    "    return(sum(i*j for i,j in zip(a,b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity=list()\n",
    "\n",
    "for i in range(len(docs_list)):\n",
    "    ttemp=list()\n",
    "    for j in range(len(docs_list)):\n",
    "        \n",
    "        ttemp.append(dot_product(frequency1[i],frequency1[j])/(mod[i]*mod[j]))\n",
    "    cosine_similarity.append(ttemp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0,\n",
       "  0.21320071635561041,\n",
       "  0.5720775535473553,\n",
       "  0.30151134457776363,\n",
       "  0.30151134457776363],\n",
       " [0.21320071635561041,\n",
       "  0.9999999999999998,\n",
       "  0.22360679774997896,\n",
       "  0.35355339059327373,\n",
       "  0.35355339059327373],\n",
       " [0.5720775535473553,\n",
       "  0.22360679774997896,\n",
       "  0.9999999999999998,\n",
       "  0.31622776601683794,\n",
       "  0.31622776601683794],\n",
       " [0.30151134457776363, 0.35355339059327373, 0.31622776601683794, 1.0, 1.0],\n",
       " [0.30151134457776363, 0.35355339059327373, 0.31622776601683794, 1.0, 1.0]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
